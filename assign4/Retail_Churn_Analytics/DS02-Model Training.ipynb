{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cf2ee3a",
   "metadata": {},
   "source": [
    "## Customer Churn Analytics - Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88df14c0",
   "metadata": {},
   "source": [
    "We will be working with three tables that contains Customer data, Communications data and Order data for a Retail Store. These dataset can be used to understand the consumer behaviour to predict churn, in this example.\n",
    "\n",
    "These datasets were generated for this demo using a Kaggle dataset below.\n",
    "\n",
    "Reference: https://www.kaggle.com/uttamp/store-data\n",
    "\n",
    "\n",
    "In this notebook, we will work with the CURATED_CUSTOMER_CHURN table that is created by the Feature Engineering notebook and train a classification model using XGBoost to predict customer churn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a17fa74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.snowpark.session import Session\n",
    "from snowflake.snowpark import functions as F\n",
    "import snowflake.snowpark.types as T\n",
    "import preprocessing as pp\n",
    "from snowflake.snowpark.functions import sproc, col\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import joblib\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import confusion_matrix, balanced_accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9628623",
   "metadata": {},
   "source": [
    "## 1. Create a Snowpark Session\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07a7b443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(CURRENT_WAREHOUSE()='BI_MEDIUM_WH', CURRENT_DATABASE()='SUMMIT_DB', CURRENT_SCHEMA()='CHURN')]\n"
     ]
    }
   ],
   "source": [
    "with open('creds.json') as f:\n",
    "        data = json.load(f)\n",
    "        connection_parameters = {\n",
    "          'account': data['account'],\n",
    "          'user': data['user'],\n",
    "          'password': data['password'], #getpass.getpass(),\n",
    "          'schema': data['schema'],\n",
    "          'database': data['database'],\n",
    "          'warehouse': data['warehouse']}\n",
    "session = Session.builder.configs(connection_parameters).create()\n",
    "print(session.sql('select current_warehouse(), current_database(), current_schema()').collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e7d9fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The version of package pandas in the local environment is 1.5.2, which does not fit the criteria for the requirement pandas. Your UDF might not work when the package version is different between the server and your local environment\n",
      "The version of package numpy in the local environment is 1.23.5, which does not fit the criteria for the requirement numpy. Your UDF might not work when the package version is different between the server and your local environment\n",
      "The version of package xgboost in the local environment is 1.7.1, which does not fit the criteria for the requirement xgboost. Your UDF might not work when the package version is different between the server and your local environment\n"
     ]
    }
   ],
   "source": [
    "session.add_import('preprocessing')\n",
    "session.add_packages('snowflake-snowpark-python','scipy', 'scikit-learn', 'pandas', 'numpy', 'joblib', 'xgboost', 'cachetools')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a43a21",
   "metadata": {},
   "source": [
    "## 2. Create stages for models and udfs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fbf608f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(status='Stage area MODELS successfully created.')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"create or replace stage models\" +\\\n",
    "        \" directory = (enable = true)\" +\\\n",
    "        \" copy_options = (on_error='skip_file')\"\n",
    "        \n",
    "session.sql(query).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e614b0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(status='Stage area UDF successfully created.')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"create or replace stage udf\" +\\\n",
    "        \" copy_options = (on_error='skip_file')\"\n",
    "        \n",
    "session.sql(query).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "60c11f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_file(session, model, path):\n",
    "  input_stream = io.BytesIO()\n",
    "  joblib.dump(model, input_stream)\n",
    "  session._conn._cursor.upload_stream(input_stream, path)\n",
    "  return \"successfully created file: \" + path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542b289f",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering and XGBoost Model Training in Python Stored Procedures\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751e43ef",
   "metadata": {},
   "source": [
    "First, we will do feature engineering to add new features, drop features and apply one-hot encoding to categorical fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "371c3df0",
   "metadata": {},
   "outputs": [
    {
     "ename": "SnowparkSessionException",
     "evalue": "(1409): More than one active session is detected. When you call function 'udf' or use decorator '@udf', you must specify the 'session' parameter if you created multiple sessions.Alternatively, you can use 'session.udf.register' to register UDFs",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSnowparkSessionException\u001b[0m                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mSUCCESS\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     18\u001b[0m \u001b[39m# Create an instance of StoredProcedure using the sproc() function\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m data_prep_sp \u001b[39m=\u001b[39m sproc(dataPrep, replace\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/py38_env/lib/python3.8/site-packages/snowflake/snowpark/functions.py:3606\u001b[0m, in \u001b[0;36msproc\u001b[0;34m(func, return_type, input_types, name, is_permanent, stage_location, imports, packages, replace, session, parallel, statement_params, execute_as, strict)\u001b[0m\n\u001b[1;32m   3499\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msproc\u001b[39m(\n\u001b[1;32m   3500\u001b[0m     func: Optional[Callable] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   3501\u001b[0m     \u001b[39m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3514\u001b[0m     strict: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m   3515\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Union[StoredProcedure, functools\u001b[39m.\u001b[39mpartial]:\n\u001b[1;32m   3516\u001b[0m     \u001b[39m\"\"\"Registers a Python function as a Snowflake Python stored procedure and returns the stored procedure.\u001b[39;00m\n\u001b[1;32m   3517\u001b[0m \n\u001b[1;32m   3518\u001b[0m \u001b[39m    It can be used as either a function call or a decorator. In most cases you work with a single session.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3604\u001b[0m \u001b[39m        :class:`~snowflake.snowpark.stored_procedure.StoredProcedureRegistration`\u001b[39;00m\n\u001b[1;32m   3605\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3606\u001b[0m     session \u001b[39m=\u001b[39m session \u001b[39mor\u001b[39;00m snowflake\u001b[39m.\u001b[39;49msnowpark\u001b[39m.\u001b[39;49msession\u001b[39m.\u001b[39;49m_get_active_session()\n\u001b[1;32m   3607\u001b[0m     \u001b[39mif\u001b[39;00m func \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   3608\u001b[0m         \u001b[39mreturn\u001b[39;00m functools\u001b[39m.\u001b[39mpartial(\n\u001b[1;32m   3609\u001b[0m             session\u001b[39m.\u001b[39msproc\u001b[39m.\u001b[39mregister,\n\u001b[1;32m   3610\u001b[0m             return_type\u001b[39m=\u001b[39mreturn_type,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3621\u001b[0m             strict\u001b[39m=\u001b[39mstrict,\n\u001b[1;32m   3622\u001b[0m         )\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/py38_env/lib/python3.8/site-packages/snowflake/snowpark/session.py:140\u001b[0m, in \u001b[0;36m_get_active_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mnext\u001b[39m(\u001b[39miter\u001b[39m(_active_sessions))\n\u001b[1;32m    139\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mlen\u001b[39m(_active_sessions) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 140\u001b[0m     \u001b[39mraise\u001b[39;00m SnowparkClientExceptionMessages\u001b[39m.\u001b[39mMORE_THAN_ONE_ACTIVE_SESSIONS()\n\u001b[1;32m    141\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    142\u001b[0m     \u001b[39mraise\u001b[39;00m SnowparkClientExceptionMessages\u001b[39m.\u001b[39mSERVER_NO_DEFAULT_SESSION()\n",
      "\u001b[0;31mSnowparkSessionException\u001b[0m: (1409): More than one active session is detected. When you call function 'udf' or use decorator '@udf', you must specify the 'session' parameter if you created multiple sessions.Alternatively, you can use 'session.udf.register' to register UDFs"
     ]
    }
   ],
   "source": [
    "src_table_name = 'TRANSFORMED_CUSTOMER_CHURN'\n",
    "tgt_table_name = 'CURATED_CUSTOMER_CHURN'\n",
    "\n",
    "def preprocessData(dfRaw):\n",
    "    dfTransformed = dfRaw.drop(dfRaw[\"CREATED_DT\"],dfRaw[\"FIRST_ORDER_DT\"],dfRaw[\"LAST_ORDER_DT\"])\n",
    "    encoder_input_cols = [\"FAV_DELIVERY_DAY\", \"CITY\"]\n",
    "    ohe = pp.OneHotEncoder(input_cols=encoder_input_cols)\n",
    "    ohe.fit(dfTransformed)\n",
    "    ohe_dfTransformed = ohe.transform(dfTransformed)\n",
    "    return ohe_dfTransformed\n",
    "\n",
    "def dataPrep(session: Session) -> str:\n",
    "    src_df = session.table(src_table_name)\n",
    "    df=preprocessData(src_df)\n",
    "    df.write.mode(\"overwrite\").save_as_table(tgt_table_name)\n",
    "    return 'SUCCESS'\n",
    "\n",
    "# Create an instance of StoredProcedure using the sproc() function\n",
    "data_prep_sp = sproc(dataPrep, replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1e91d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SUCCESS'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_prep_sp()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7169a7b6",
   "metadata": {},
   "source": [
    "![Original Data Frame](images/image1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ed2282",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "no numeric data to plot",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m#plot refill against customers retained\u001b[39;00m\n\u001b[1;32m      2\u001b[0m df_retained \u001b[39m=\u001b[39m session\u001b[39m.\u001b[39mtable(tgt_table_name)\u001b[39m.\u001b[39mselect(\u001b[39m'\u001b[39m\u001b[39mCUSTOMER_ID\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mRETAINED\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mREFILL\u001b[39m\u001b[39m'\u001b[39m)\\\n\u001b[1;32m      3\u001b[0m              \u001b[39m.\u001b[39mgroup_by(col(\u001b[39m'\u001b[39m\u001b[39mRETAINED\u001b[39m\u001b[39m'\u001b[39m), col(\u001b[39m'\u001b[39m\u001b[39mREFILL\u001b[39m\u001b[39m'\u001b[39m)) \\\n\u001b[1;32m      4\u001b[0m              \u001b[39m.\u001b[39mcount() \\\n\u001b[1;32m      5\u001b[0m              \u001b[39m.\u001b[39mtoPandas()\n\u001b[0;32m----> 7\u001b[0m pd\u001b[39m.\u001b[39;49mpivot_table(df_retained,\n\u001b[1;32m      8\u001b[0m               values\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mCOUNT\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m      9\u001b[0m               index\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mRETAINED\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     10\u001b[0m               columns\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mREFILL\u001b[39;49m\u001b[39m'\u001b[39;49m) \\\n\u001b[1;32m     11\u001b[0m              \u001b[39m.\u001b[39;49mplot\u001b[39m.\u001b[39;49mbar()\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/py38_env/lib/python3.8/site-packages/pandas/plotting/_core.py:1159\u001b[0m, in \u001b[0;36mPlotAccessor.bar\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m   1071\u001b[0m \u001b[39m@Appender\u001b[39m(\n\u001b[1;32m   1072\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1073\u001b[0m \u001b[39m    See Also\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1148\u001b[0m \u001b[39m@Appender\u001b[39m(_bar_or_line_doc)\n\u001b[1;32m   1149\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbar\u001b[39m(\u001b[39mself\u001b[39m, x\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m PlotAccessor:\n\u001b[1;32m   1150\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1151\u001b[0m \u001b[39m    Vertical bar plot.\u001b[39;00m\n\u001b[1;32m   1152\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1157\u001b[0m \u001b[39m    other axis represents a measured value.\u001b[39;00m\n\u001b[1;32m   1158\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1159\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(kind\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mbar\u001b[39;49m\u001b[39m\"\u001b[39;49m, x\u001b[39m=\u001b[39;49mx, y\u001b[39m=\u001b[39;49my, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/py38_env/lib/python3.8/site-packages/pandas/plotting/_core.py:1000\u001b[0m, in \u001b[0;36mPlotAccessor.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    997\u001b[0m             label_name \u001b[39m=\u001b[39m label_kw \u001b[39mor\u001b[39;00m data\u001b[39m.\u001b[39mcolumns\n\u001b[1;32m    998\u001b[0m             data\u001b[39m.\u001b[39mcolumns \u001b[39m=\u001b[39m label_name\n\u001b[0;32m-> 1000\u001b[0m \u001b[39mreturn\u001b[39;00m plot_backend\u001b[39m.\u001b[39;49mplot(data, kind\u001b[39m=\u001b[39;49mkind, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/py38_env/lib/python3.8/site-packages/pandas/plotting/_matplotlib/__init__.py:71\u001b[0m, in \u001b[0;36mplot\u001b[0;34m(data, kind, **kwargs)\u001b[0m\n\u001b[1;32m     69\u001b[0m         kwargs[\u001b[39m\"\u001b[39m\u001b[39max\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(ax, \u001b[39m\"\u001b[39m\u001b[39mleft_ax\u001b[39m\u001b[39m\"\u001b[39m, ax)\n\u001b[1;32m     70\u001b[0m plot_obj \u001b[39m=\u001b[39m PLOT_CLASSES[kind](data, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m---> 71\u001b[0m plot_obj\u001b[39m.\u001b[39;49mgenerate()\n\u001b[1;32m     72\u001b[0m plot_obj\u001b[39m.\u001b[39mdraw()\n\u001b[1;32m     73\u001b[0m \u001b[39mreturn\u001b[39;00m plot_obj\u001b[39m.\u001b[39mresult\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/py38_env/lib/python3.8/site-packages/pandas/plotting/_matplotlib/core.py:450\u001b[0m, in \u001b[0;36mMPLPlot.generate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    449\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_args_adjust()\n\u001b[0;32m--> 450\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_compute_plot_data()\n\u001b[1;32m    451\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setup_subplots()\n\u001b[1;32m    452\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_plot()\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/py38_env/lib/python3.8/site-packages/pandas/plotting/_matplotlib/core.py:635\u001b[0m, in \u001b[0;36mMPLPlot._compute_plot_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[39m# no non-numeric frames or series allowed\u001b[39;00m\n\u001b[1;32m    634\u001b[0m \u001b[39mif\u001b[39;00m is_empty:\n\u001b[0;32m--> 635\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mno numeric data to plot\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    637\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m numeric_data\u001b[39m.\u001b[39mapply(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_convert_to_ndarray)\n",
      "\u001b[0;31mTypeError\u001b[0m: no numeric data to plot"
     ]
    }
   ],
   "source": [
    "#plot refill against customers retained\n",
    "df_retained = session.table(tgt_table_name).select('CUSTOMER_ID','RETAINED','REFILL')\\\n",
    "             .group_by(col('RETAINED'), col('REFILL')) \\\n",
    "             .count() \\\n",
    "             .toPandas()\n",
    "\n",
    "pd.pivot_table(df_retained,\n",
    "              values='COUNT',\n",
    "              index='RETAINED',\n",
    "              columns='REFILL') \\\n",
    "             .plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0f8c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(session: Session) -> str:\n",
    "    snowdf = session.table(tgt_table_name).drop('CUSTOMER_ID')\n",
    "    # split the train and test set\n",
    "    snowdf_train, snowdf_test = snowdf.random_split([0.8, 0.2], seed=82) # use seed to make the split repeatable\n",
    "    \n",
    "    # save the train and test sets as time stamped tables in Snowflake \n",
    "    snowdf_train.write.mode(\"overwrite\").save_as_table(tgt_table_name + \"_TRAIN\")\n",
    "    snowdf_test.write.mode(\"overwrite\").save_as_table(tgt_table_name +\"_TEST\")\n",
    "    \n",
    "    # Imputing missing values in numeric columns\n",
    "    numeric_types = [T.DecimalType, T.LongType, T.DoubleType, T.FloatType, T.IntegerType]\n",
    "    numeric_columns = [c.name for c in snowdf.schema.fields if type(c.datatype) in numeric_types]\n",
    "    categorical_columns = [c.name for c in snowdf.schema.fields if type(c.datatype) not in numeric_types]\n",
    "    for column in numeric_columns:\n",
    "        snowdf = snowdf.fillna(snowdf.select(F.median(column)).collect()[0][0], column)\n",
    "        \n",
    "    cust = snowdf_train.drop(\"RETAINED\").to_pandas() # drop labels for training set\n",
    "    cust_labels = snowdf_train.select(\"RETAINED\").to_pandas()\n",
    "    cust_test = snowdf_test.drop(\"RETAINED\").to_pandas()\n",
    "    cust_test_labels = snowdf_test.select(\"RETAINED\").to_pandas()\n",
    "  \n",
    "    standardizer = StandardScaler()\n",
    "    xgbc_classifier = XGBClassifier(\n",
    "          colsample_bytree=0.6621869047211867,\n",
    "          learning_rate=0.006344788828608473,\n",
    "          max_depth=6,\n",
    "          min_child_weight=8,\n",
    "          n_estimators=1115,\n",
    "          n_jobs=100,\n",
    "          subsample=0.26613420034295865,\n",
    "          verbosity=0,\n",
    "          random_state=829929877,\n",
    "          nthread=1\n",
    "    )\n",
    "    full_pipeline = Pipeline([\n",
    "            ('standardizer', standardizer),\n",
    "            ('classfier', xgbc_classifier)\n",
    "        ])\n",
    "\n",
    "    # fit the preprocessing pipeline and the model together\n",
    "    full_pipeline.fit(cust, cust_labels)\n",
    "    y_pred = full_pipeline.predict_proba(cust_test)[:,1]\n",
    "    predictions = [round(value) for value in y_pred]\n",
    "    balanced_accuracy =  balanced_accuracy_score(cust_test_labels, predictions)\n",
    "    print(\"Model testing completed.\\n   - Model Balanced Accuracy: %.2f%%\" % (balanced_accuracy * 100.0))\n",
    "    \n",
    "    #Confusion Matrix\n",
    "    cm = confusion_matrix(cust_test_labels, predictions)\n",
    "    TN, FP, FN, TP = confusion_matrix(cust_test_labels, predictions).ravel()\n",
    "    accuracy =  (TP+TN) /(TP+FP+TN+FN)\n",
    "   \n",
    "    # save the full pipeline including the model\n",
    "    save_file(session, full_pipeline, \"@MODELS/cust_churn.joblib\")\n",
    "    return accuracy\n",
    "\n",
    "# Create an instance of StoredProcedure using the sproc() function\n",
    "train_model_sp = sproc(train_model, replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251caa8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to execute query [queryID: 01a90c2b-0504-3574-0035-cd870003a516] CALL \"SUMMIT_DB\".\"CHURN\".SNOWPARK_TEMP_PROCEDURE_FPBXI1IO13()\n",
      "100357 (P0000): Python Interpreter Error:\n",
      "Traceback (most recent call last):\n",
      "  File \"_udf_code.py\", line 7, in compute\n",
      "  File \"/var/folders/7_/dz3yj_1n1rqbtq3n6qnnktsh0000gn/T/ipykernel_7359/2235441279.py\", line 41, in train_model\n",
      "  File \"/usr/lib/python_udf/418f2eb2da12ecb131fa7f40d8988ff00193ef395077c7c5091900e5b514db9c/lib/python3.8/site-packages/sklearn/pipeline.py\", line 378, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/usr/lib/python_udf/418f2eb2da12ecb131fa7f40d8988ff00193ef395077c7c5091900e5b514db9c/lib/python3.8/site-packages/sklearn/pipeline.py\", line 336, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"/usr/lib/python_udf/418f2eb2da12ecb131fa7f40d8988ff00193ef395077c7c5091900e5b514db9c/lib/python3.8/site-packages/joblib/memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/usr/lib/python_udf/418f2eb2da12ecb131fa7f40d8988ff00193ef395077c7c5091900e5b514db9c/lib/python3.8/site-packages/sklearn/pipeline.py\", line 870, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/usr/lib/python_udf/418f2eb2da12ecb131fa7f40d8988ff00193ef395077c7c5091900e5b514db9c/lib/python3.8/site-packages/sklearn/base.py\", line 870, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/usr/lib/python_udf/418f2eb2da12ecb131fa7f40d8988ff00193ef395077c7c5091900e5b514db9c/lib/python3.8/site-packages/sklearn/preprocessing/_data.py\", line 809, in fit\n",
      "    return self.partial_fit(X, y, sample_weight)\n",
      "  File \"/usr/lib/python_udf/418f2eb2da12ecb131fa7f40d8988ff00193ef395077c7c5091900e5b514db9c/lib/python3.8/site-packages/sklearn/preprocessing/_data.py\", line 844, in partial_fit\n",
      "    X = self._validate_data(\n",
      "  File \"/usr/lib/python_udf/418f2eb2da12ecb131fa7f40d8988ff00193ef395077c7c5091900e5b514db9c/lib/python3.8/site-packages/sklearn/base.py\", line 577, in _validate_data\n",
      "    X = check_array(X, input_name=\"X\", **check_params)\n",
      "  File \"/usr/lib/python_udf/418f2eb2da12ecb131fa7f40d8988ff00193ef395077c7c5091900e5b514db9c/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 909, in check_array\n",
      "    raise ValueError(\n",
      "ValueError: Found array with 0 sample(s) (shape=(0, 9)) while a minimum of 1 is required by StandardScaler.\n",
      " in function SNOWPARK_TEMP_PROCEDURE_FPBXI1IO13 with handler compute\n"
     ]
    },
    {
     "ename": "SnowparkSQLException",
     "evalue": "(1304): 01a90c2b-0504-3574-0035-cd870003a516: 100357 (P0000): Python Interpreter Error:\nTraceback (most recent call last):\n  File \"_udf_code.py\", line 7, in compute\n  File \"/var/folders/7_/dz3yj_1n1rqbtq3n6qnnktsh0000gn/T/ipykernel_7359/2235441279.py\", line 41, in train_model\n  File \"/usr/lib/python_udf/418f2eb2da12ecb131fa7f40d8988ff00193ef395077c7c5091900e5b514db9c/lib/python3.8/site-packages/sklearn/pipeline.py\", line 378, in fit\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/usr/lib/python_udf/418f2eb2da12ecb131fa7f40d8988ff00193ef395077c7c5091900e5b514db9c/lib/python3.8/site-packages/sklearn/pipeline.py\", line 336, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/usr/lib/python_udf/418f2eb2da12ecb131fa7f40d8988ff00193ef395077c7c5091900e5b514db9c/lib/python3.8/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/usr/lib/python_udf/418f2eb2da12ecb131fa7f40d8988ff00193ef395077c7c5091900e5b514db9c/lib/python3.8/site-packages/sklearn/pipeline.py\", line 870, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"/usr/lib/python_udf/418f2eb2da12ecb131fa7f40d8988ff00193ef395077c7c5091900e5b514db9c/lib/python3.8/site-packages/sklearn/base.py\", line 870, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n  File \"/usr/lib/python_udf/418f2eb2da12ecb131fa7f40d8988ff00193ef395077c7c5091900e5b514db9c/lib/python3.8/site-packages/sklearn/preprocessing/_data.py\", line 809, in fit\n    return self.partial_fit(X, y, sample_weight)\n  File \"/usr/lib/python_udf/418f2eb2da12ecb131fa7f40d8988ff00193ef395077c7c5091900e5b514db9c/lib/python3.8/site-packages/sklearn/preprocessing/_data.py\", line 844, in partial_fit\n    X = self._validate_data(\n  File \"/usr/lib/python_udf/418f2eb2da12ecb131fa7f40d8988ff00193ef395077c7c5091900e5b514db9c/lib/python3.8/site-packages/sklearn/base.py\", line 577, in _validate_data\n    X = check_array(X, input_name=\"X\", **check_params)\n  File \"/usr/lib/python_udf/418f2eb2da12ecb131fa7f40d8988ff00193ef395077c7c5091900e5b514db9c/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 909, in check_array\n    raise ValueError(\nValueError: Found array with 0 sample(s) (shape=(0, 9)) while a minimum of 1 is required by StandardScaler.\n in function SNOWPARK_TEMP_PROCEDURE_FPBXI1IO13 with handler compute",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSnowparkSQLException\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_model_sp()\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/py38_env/lib/python3.8/site-packages/snowflake/snowpark/stored_procedure.py:87\u001b[0m, in \u001b[0;36mStoredProcedure.__call__\u001b[0;34m(self, session, *args)\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     81\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIncorrect number of arguments passed to the stored procedure. Expected: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_input_types)\u001b[39m}\u001b[39;00m\u001b[39m, Found: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(args)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     82\u001b[0m     )\n\u001b[1;32m     84\u001b[0m session\u001b[39m.\u001b[39m_conn\u001b[39m.\u001b[39m_telemetry_client\u001b[39m.\u001b[39msend_function_usage_telemetry(\n\u001b[1;32m     85\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mStoredProcedure.__call__\u001b[39m\u001b[39m\"\u001b[39m, TelemetryField\u001b[39m.\u001b[39mFUNC_CAT_USAGE\u001b[39m.\u001b[39mvalue\n\u001b[1;32m     86\u001b[0m )\n\u001b[0;32m---> 87\u001b[0m \u001b[39mreturn\u001b[39;00m session\u001b[39m.\u001b[39;49mcall(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname, \u001b[39m*\u001b[39;49margs)\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/py38_env/lib/python3.8/site-packages/snowflake/snowpark/session.py:1801\u001b[0m, in \u001b[0;36mSession.call\u001b[0;34m(self, sproc_name, *args)\u001b[0m\n\u001b[1;32m   1799\u001b[0m df \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msql(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCALL \u001b[39m\u001b[39m{\u001b[39;00msproc_name\u001b[39m}\u001b[39;00m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(sql_args)\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1800\u001b[0m set_api_call_source(df, \u001b[39m\"\u001b[39m\u001b[39mSession.call\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1801\u001b[0m \u001b[39mreturn\u001b[39;00m df\u001b[39m.\u001b[39;49mcollect()[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/py38_env/lib/python3.8/site-packages/snowflake/snowpark/_internal/telemetry.py:138\u001b[0m, in \u001b[0;36mdf_collect_api_telemetry.<locals>.wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    136\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrap\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    137\u001b[0m     \u001b[39mwith\u001b[39;00m args[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39m_session\u001b[39m.\u001b[39mquery_history() \u001b[39mas\u001b[39;00m query_history:\n\u001b[0;32m--> 138\u001b[0m         result \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    139\u001b[0m     plan \u001b[39m=\u001b[39m args[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39m_select_statement \u001b[39mor\u001b[39;00m args[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39m_plan\n\u001b[1;32m    140\u001b[0m     api_calls \u001b[39m=\u001b[39m [\n\u001b[1;32m    141\u001b[0m         \u001b[39m*\u001b[39mplan\u001b[39m.\u001b[39mapi_calls,\n\u001b[1;32m    142\u001b[0m         {TelemetryField\u001b[39m.\u001b[39mNAME\u001b[39m.\u001b[39mvalue: \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDataFrame.\u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m},\n\u001b[1;32m    143\u001b[0m     ]\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/py38_env/lib/python3.8/site-packages/snowflake/snowpark/dataframe.py:549\u001b[0m, in \u001b[0;36mDataFrame.collect\u001b[0;34m(self, statement_params, block)\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[39m@df_collect_api_telemetry\u001b[39m\n\u001b[1;32m    534\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcollect\u001b[39m(\n\u001b[1;32m    535\u001b[0m     \u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m, statement_params: Optional[Dict[\u001b[39mstr\u001b[39m, \u001b[39mstr\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, block: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    536\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Union[List[Row], AsyncJob]:\n\u001b[1;32m    537\u001b[0m     \u001b[39m\"\"\"Executes the query representing this DataFrame and returns the result as a\u001b[39;00m\n\u001b[1;32m    538\u001b[0m \u001b[39m    list of :class:`Row` objects.\u001b[39;00m\n\u001b[1;32m    539\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[39m        :meth:`collect_nowait()`\u001b[39;00m\n\u001b[1;32m    548\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 549\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_internal_collect_with_tag_no_telemetry(\n\u001b[1;32m    550\u001b[0m         statement_params\u001b[39m=\u001b[39;49mstatement_params, block\u001b[39m=\u001b[39;49mblock\n\u001b[1;32m    551\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/py38_env/lib/python3.8/site-packages/snowflake/snowpark/dataframe.py:584\u001b[0m, in \u001b[0;36mDataFrame._internal_collect_with_tag_no_telemetry\u001b[0;34m(self, statement_params, block, data_type)\u001b[0m\n\u001b[1;32m    574\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_internal_collect_with_tag_no_telemetry\u001b[39m(\n\u001b[1;32m    575\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    576\u001b[0m     \u001b[39m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[39m# we should always call this method instead of collect(), to make sure the\u001b[39;00m\n\u001b[1;32m    583\u001b[0m     \u001b[39m# query tag is set properly.\u001b[39;00m\n\u001b[0;32m--> 584\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_session\u001b[39m.\u001b[39;49m_conn\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    585\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_plan,\n\u001b[1;32m    586\u001b[0m         block\u001b[39m=\u001b[39;49mblock,\n\u001b[1;32m    587\u001b[0m         data_type\u001b[39m=\u001b[39;49mdata_type,\n\u001b[1;32m    588\u001b[0m         _statement_params\u001b[39m=\u001b[39;49mcreate_or_update_statement_params_with_query_tag(\n\u001b[1;32m    589\u001b[0m             statement_params, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_session\u001b[39m.\u001b[39;49mquery_tag, SKIP_LEVELS_THREE\n\u001b[1;32m    590\u001b[0m         ),\n\u001b[1;32m    591\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/py38_env/lib/python3.8/site-packages/snowflake/snowpark/_internal/server_connection.py:406\u001b[0m, in \u001b[0;36mServerConnection.execute\u001b[0;34m(self, plan, to_pandas, to_iter, block, data_type, **kwargs)\u001b[0m\n\u001b[1;32m    402\u001b[0m \u001b[39mif\u001b[39;00m is_in_stored_procedure() \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m block:  \u001b[39m# pragma: no cover\u001b[39;00m\n\u001b[1;32m    403\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    404\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAsync query is not supported in stored procedure yet\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    405\u001b[0m     )\n\u001b[0;32m--> 406\u001b[0m result_set, result_meta \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_result_set(\n\u001b[1;32m    407\u001b[0m     plan, to_pandas, to_iter, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs, block\u001b[39m=\u001b[39;49mblock, data_type\u001b[39m=\u001b[39;49mdata_type\n\u001b[1;32m    408\u001b[0m )\n\u001b[1;32m    409\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m block:\n\u001b[1;32m    410\u001b[0m     \u001b[39mreturn\u001b[39;00m result_set\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/py38_env/lib/python3.8/site-packages/snowflake/snowpark/_internal/analyzer/snowflake_plan.py:154\u001b[0m, in \u001b[0;36mSnowflakePlan.Decorator.wrap_exception.<locals>.wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m     ne \u001b[39m=\u001b[39m SnowparkClientExceptionMessages\u001b[39m.\u001b[39mSQL_EXCEPTION_FROM_PROGRAMMING_ERROR(\n\u001b[1;32m    152\u001b[0m         e\n\u001b[1;32m    153\u001b[0m     )\n\u001b[0;32m--> 154\u001b[0m     \u001b[39mraise\u001b[39;00m ne\u001b[39m.\u001b[39mwith_traceback(tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/py38_env/lib/python3.8/site-packages/snowflake/snowpark/_internal/analyzer/snowflake_plan.py:87\u001b[0m, in \u001b[0;36mSnowflakePlan.Decorator.wrap_exception.<locals>.wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrap\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     86\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 87\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     88\u001b[0m     \u001b[39mexcept\u001b[39;00m snowflake\u001b[39m.\u001b[39mconnector\u001b[39m.\u001b[39merrors\u001b[39m.\u001b[39mProgrammingError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     89\u001b[0m         tb \u001b[39m=\u001b[39m sys\u001b[39m.\u001b[39mexc_info()[\u001b[39m2\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/py38_env/lib/python3.8/site-packages/snowflake/snowpark/_internal/server_connection.py:494\u001b[0m, in \u001b[0;36mServerConnection.get_result_set\u001b[0;34m(self, plan, to_pandas, to_iter, block, data_type, **kwargs)\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[39mfor\u001b[39;00m holder, id_ \u001b[39min\u001b[39;00m placeholders\u001b[39m.\u001b[39mitems():\n\u001b[1;32m    493\u001b[0m     final_query \u001b[39m=\u001b[39m final_query\u001b[39m.\u001b[39mreplace(holder, id_)\n\u001b[0;32m--> 494\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_query(\n\u001b[1;32m    495\u001b[0m     final_query,\n\u001b[1;32m    496\u001b[0m     to_pandas,\n\u001b[1;32m    497\u001b[0m     to_iter \u001b[39mand\u001b[39;49;00m (i \u001b[39m==\u001b[39;49m \u001b[39mlen\u001b[39;49m(plan\u001b[39m.\u001b[39;49mqueries) \u001b[39m-\u001b[39;49m \u001b[39m1\u001b[39;49m),\n\u001b[1;32m    498\u001b[0m     is_ddl_on_temp_object\u001b[39m=\u001b[39;49mquery\u001b[39m.\u001b[39;49mis_ddl_on_temp_object,\n\u001b[1;32m    499\u001b[0m     block\u001b[39m=\u001b[39;49m\u001b[39mnot\u001b[39;49;00m is_last,\n\u001b[1;32m    500\u001b[0m     data_type\u001b[39m=\u001b[39;49mdata_type,\n\u001b[1;32m    501\u001b[0m     async_job_plan\u001b[39m=\u001b[39;49mplan,\n\u001b[1;32m    502\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    503\u001b[0m )\n\u001b[1;32m    504\u001b[0m placeholders[query\u001b[39m.\u001b[39mquery_id_place_holder] \u001b[39m=\u001b[39m (\n\u001b[1;32m    505\u001b[0m     result[\u001b[39m\"\u001b[39m\u001b[39msfqid\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_last \u001b[39melse\u001b[39;00m result\u001b[39m.\u001b[39mquery_id\n\u001b[1;32m    506\u001b[0m )\n\u001b[1;32m    507\u001b[0m result_meta \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cursor\u001b[39m.\u001b[39mdescription\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/py38_env/lib/python3.8/site-packages/snowflake/snowpark/_internal/server_connection.py:104\u001b[0m, in \u001b[0;36mServerConnection._Decorator.wrap_exception.<locals>.wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[39mraise\u001b[39;00m SnowparkClientExceptionMessages\u001b[39m.\u001b[39mSERVER_SESSION_EXPIRED(\n\u001b[1;32m    101\u001b[0m         ex\u001b[39m.\u001b[39mcause\n\u001b[1;32m    102\u001b[0m     )\n\u001b[1;32m    103\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m ex:\n\u001b[0;32m--> 104\u001b[0m     \u001b[39mraise\u001b[39;00m ex\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/py38_env/lib/python3.8/site-packages/snowflake/snowpark/_internal/server_connection.py:98\u001b[0m, in \u001b[0;36mServerConnection._Decorator.wrap_exception.<locals>.wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[39mraise\u001b[39;00m SnowparkClientExceptionMessages\u001b[39m.\u001b[39mSERVER_SESSION_HAS_BEEN_CLOSED()\n\u001b[1;32m     97\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 98\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     99\u001b[0m \u001b[39mexcept\u001b[39;00m ReauthenticationRequest \u001b[39mas\u001b[39;00m ex:\n\u001b[1;32m    100\u001b[0m     \u001b[39mraise\u001b[39;00m SnowparkClientExceptionMessages\u001b[39m.\u001b[39mSERVER_SESSION_EXPIRED(\n\u001b[1;32m    101\u001b[0m         ex\u001b[39m.\u001b[39mcause\n\u001b[1;32m    102\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/py38_env/lib/python3.8/site-packages/snowflake/snowpark/_internal/server_connection.py:333\u001b[0m, in \u001b[0;36mServerConnection.run_query\u001b[0;34m(self, query, to_pandas, to_iter, is_ddl_on_temp_object, block, data_type, async_job_plan, **kwargs)\u001b[0m\n\u001b[1;32m    331\u001b[0m     query_id_log \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m [queryID: \u001b[39m\u001b[39m{\u001b[39;00mex\u001b[39m.\u001b[39msfqid\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(ex, \u001b[39m\"\u001b[39m\u001b[39msfqid\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    332\u001b[0m     logger\u001b[39m.\u001b[39merror(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFailed to execute query\u001b[39m\u001b[39m{\u001b[39;00mquery_id_log\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mquery\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mex\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 333\u001b[0m     \u001b[39mraise\u001b[39;00m ex\n\u001b[1;32m    335\u001b[0m \u001b[39m# fetch_pandas_all/batches() only works for SELECT statements\u001b[39;00m\n\u001b[1;32m    336\u001b[0m \u001b[39m# We call fetchall() if fetch_pandas_all/batches() fails,\u001b[39;00m\n\u001b[1;32m    337\u001b[0m \u001b[39m# because when the query plan has multiple queries, it will\u001b[39;00m\n\u001b[1;32m    338\u001b[0m \u001b[39m# have non-select statements, and it shouldn't fail if the user\u001b[39;00m\n\u001b[1;32m    339\u001b[0m \u001b[39m# calls to_pandas() to execute the query.\u001b[39;00m\n\u001b[1;32m    340\u001b[0m \u001b[39mif\u001b[39;00m block:\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/py38_env/lib/python3.8/site-packages/snowflake/snowpark/_internal/server_connection.py:317\u001b[0m, in \u001b[0;36mServerConnection.run_query\u001b[0;34m(self, query, to_pandas, to_iter, is_ddl_on_temp_object, block, data_type, async_job_plan, **kwargs)\u001b[0m\n\u001b[1;32m    315\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39m_statement_params\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mSNOWPARK_SKIP_TXN_COMMIT_IN_DDL\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    316\u001b[0m \u001b[39mif\u001b[39;00m block:\n\u001b[0;32m--> 317\u001b[0m     results_cursor \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cursor\u001b[39m.\u001b[39;49mexecute(query, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    318\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnotify_query_listeners(\n\u001b[1;32m    319\u001b[0m         QueryRecord(results_cursor\u001b[39m.\u001b[39msfqid, results_cursor\u001b[39m.\u001b[39mquery)\n\u001b[1;32m    320\u001b[0m     )\n\u001b[1;32m    321\u001b[0m     logger\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExecute query [queryID: \u001b[39m\u001b[39m{\u001b[39;00mresults_cursor\u001b[39m.\u001b[39msfqid\u001b[39m}\u001b[39;00m\u001b[39m] \u001b[39m\u001b[39m{\u001b[39;00mquery\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/py38_env/lib/python3.8/site-packages/snowflake/connector/cursor.py:796\u001b[0m, in \u001b[0;36mSnowflakeCursor.execute\u001b[0;34m(self, command, params, _bind_stage, timeout, _exec_async, _no_retry, _do_reset, _put_callback, _put_azure_callback, _put_callback_output_stream, _get_callback, _get_azure_callback, _get_callback_output_stream, _show_progress_bar, _statement_params, _is_internal, _describe_only, _no_results, _is_put_get, _raise_put_get_error, _force_put_overwrite, file_stream)\u001b[0m\n\u001b[1;32m    792\u001b[0m     is_integrity_error \u001b[39m=\u001b[39m (\n\u001b[1;32m    793\u001b[0m         code \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m100072\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    794\u001b[0m     )  \u001b[39m# NULL result in a non-nullable column\u001b[39;00m\n\u001b[1;32m    795\u001b[0m     error_class \u001b[39m=\u001b[39m IntegrityError \u001b[39mif\u001b[39;00m is_integrity_error \u001b[39melse\u001b[39;00m ProgrammingError\n\u001b[0;32m--> 796\u001b[0m     Error\u001b[39m.\u001b[39;49merrorhandler_wrapper(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconnection, \u001b[39mself\u001b[39;49m, error_class, errvalue)\n\u001b[1;32m    797\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/py38_env/lib/python3.8/site-packages/snowflake/connector/errors.py:275\u001b[0m, in \u001b[0;36mError.errorhandler_wrapper\u001b[0;34m(connection, cursor, error_class, error_value)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m    253\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39merrorhandler_wrapper\u001b[39m(\n\u001b[1;32m    254\u001b[0m     connection: SnowflakeConnection \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    257\u001b[0m     error_value: \u001b[39mdict\u001b[39m[\u001b[39mstr\u001b[39m, \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m \u001b[39mbool\u001b[39m \u001b[39m|\u001b[39m \u001b[39mint\u001b[39m],\n\u001b[1;32m    258\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    259\u001b[0m     \u001b[39m\"\"\"Error handler wrapper that calls the errorhandler method.\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \n\u001b[1;32m    261\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[39m        exception to the first handler in that order.\u001b[39;00m\n\u001b[1;32m    273\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 275\u001b[0m     handed_over \u001b[39m=\u001b[39m Error\u001b[39m.\u001b[39;49mhand_to_other_handler(\n\u001b[1;32m    276\u001b[0m         connection,\n\u001b[1;32m    277\u001b[0m         cursor,\n\u001b[1;32m    278\u001b[0m         error_class,\n\u001b[1;32m    279\u001b[0m         error_value,\n\u001b[1;32m    280\u001b[0m     )\n\u001b[1;32m    281\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m handed_over:\n\u001b[1;32m    282\u001b[0m         \u001b[39mraise\u001b[39;00m Error\u001b[39m.\u001b[39merrorhandler_make_exception(\n\u001b[1;32m    283\u001b[0m             error_class,\n\u001b[1;32m    284\u001b[0m             error_value,\n\u001b[1;32m    285\u001b[0m         )\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/py38_env/lib/python3.8/site-packages/snowflake/connector/errors.py:330\u001b[0m, in \u001b[0;36mError.hand_to_other_handler\u001b[0;34m(connection, cursor, error_class, error_value)\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[39mif\u001b[39;00m cursor \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    329\u001b[0m     cursor\u001b[39m.\u001b[39mmessages\u001b[39m.\u001b[39mappend((error_class, error_value))\n\u001b[0;32m--> 330\u001b[0m     cursor\u001b[39m.\u001b[39;49merrorhandler(connection, cursor, error_class, error_value)\n\u001b[1;32m    331\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \u001b[39melif\u001b[39;00m connection \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/py38_env/lib/python3.8/site-packages/snowflake/connector/errors.py:209\u001b[0m, in \u001b[0;36mError.default_errorhandler\u001b[0;34m(connection, cursor, error_class, error_value)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m    192\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdefault_errorhandler\u001b[39m(\n\u001b[1;32m    193\u001b[0m     connection: SnowflakeConnection,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    196\u001b[0m     error_value: \u001b[39mdict\u001b[39m[\u001b[39mstr\u001b[39m, \u001b[39mstr\u001b[39m],\n\u001b[1;32m    197\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    198\u001b[0m     \u001b[39m\"\"\"Default error handler that raises an error.\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \n\u001b[1;32m    200\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[39m        A Snowflake error.\u001b[39;00m\n\u001b[1;32m    208\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 209\u001b[0m     \u001b[39mraise\u001b[39;00m error_class(\n\u001b[1;32m    210\u001b[0m         msg\u001b[39m=\u001b[39merror_value\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mmsg\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m    211\u001b[0m         errno\u001b[39m=\u001b[39merror_value\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39merrno\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m    212\u001b[0m         sqlstate\u001b[39m=\u001b[39merror_value\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39msqlstate\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m    213\u001b[0m         sfqid\u001b[39m=\u001b[39merror_value\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39msfqid\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m    214\u001b[0m         done_format_msg\u001b[39m=\u001b[39merror_value\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mdone_format_msg\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m    215\u001b[0m         connection\u001b[39m=\u001b[39mconnection,\n\u001b[1;32m    216\u001b[0m         cursor\u001b[39m=\u001b[39mcursor,\n\u001b[1;32m    217\u001b[0m     )\n",
      "\u001b[0;31mSnowparkSQLException\u001b[0m: (1304): 01a90c2b-0504-3574-0035-cd870003a516: 100357 (P0000): Python Interpreter Error:\nTraceback (most recent call last):\n  File \"_udf_code.py\", line 7, in compute\n  File \"/var/folders/7_/dz3yj_1n1rqbtq3n6qnnktsh0000gn/T/ipykernel_7359/2235441279.py\", line 41, in train_model\n  File \"/usr/lib/python_udf/418f2eb2da12ecb131fa7f40d8988ff00193ef395077c7c5091900e5b514db9c/lib/python3.8/site-packages/sklearn/pipeline.py\", line 378, in fit\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/usr/lib/python_udf/418f2eb2da12ecb131fa7f40d8988ff00193ef395077c7c5091900e5b514db9c/lib/python3.8/site-packages/sklearn/pipeline.py\", line 336, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/usr/lib/python_udf/418f2eb2da12ecb131fa7f40d8988ff00193ef395077c7c5091900e5b514db9c/lib/python3.8/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/usr/lib/python_udf/418f2eb2da12ecb131fa7f40d8988ff00193ef395077c7c5091900e5b514db9c/lib/python3.8/site-packages/sklearn/pipeline.py\", line 870, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"/usr/lib/python_udf/418f2eb2da12ecb131fa7f40d8988ff00193ef395077c7c5091900e5b514db9c/lib/python3.8/site-packages/sklearn/base.py\", line 870, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n  File \"/usr/lib/python_udf/418f2eb2da12ecb131fa7f40d8988ff00193ef395077c7c5091900e5b514db9c/lib/python3.8/site-packages/sklearn/preprocessing/_data.py\", line 809, in fit\n    return self.partial_fit(X, y, sample_weight)\n  File \"/usr/lib/python_udf/418f2eb2da12ecb131fa7f40d8988ff00193ef395077c7c5091900e5b514db9c/lib/python3.8/site-packages/sklearn/preprocessing/_data.py\", line 844, in partial_fit\n    X = self._validate_data(\n  File \"/usr/lib/python_udf/418f2eb2da12ecb131fa7f40d8988ff00193ef395077c7c5091900e5b514db9c/lib/python3.8/site-packages/sklearn/base.py\", line 577, in _validate_data\n    X = check_array(X, input_name=\"X\", **check_params)\n  File \"/usr/lib/python_udf/418f2eb2da12ecb131fa7f40d8988ff00193ef395077c7c5091900e5b514db9c/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 909, in check_array\n    raise ValueError(\nValueError: Found array with 0 sample(s) (shape=(0, 9)) while a minimum of 1 is required by StandardScaler.\n in function SNOWPARK_TEMP_PROCEDURE_FPBXI1IO13 with handler compute"
     ]
    }
   ],
   "source": [
    "train_model_sp()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899a4dbe",
   "metadata": {},
   "source": [
    "## 4. Model Inference - Creating a predict() UDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7edd025",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.0 64-bit ('3.10.0')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/Users/jiaohongmei/.pyenv/versions/3.10.0/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import cachetools\n",
    "import os\n",
    "from snowflake.snowpark.functions import udf, pandas_udf\n",
    "from snowflake.snowpark.types import PandasSeries, PandasDataFrame\n",
    "session.add_import(\"@MODELS/cust_churn.joblib\")  \n",
    "\n",
    "@cachetools.cached(cache={})\n",
    "def read_file(filename):\n",
    "       import_dir = sys._xoptions.get(\"snowflake_import_directory\")\n",
    "       if import_dir:\n",
    "              with open(os.path.join(import_dir, filename), 'rb') as file:\n",
    "                     m = joblib.load(file)\n",
    "                     return m\n",
    "\n",
    "features = ['ESENT', 'EOPENRATE', 'ECLICKRATE', 'PAPERLESS', 'AVG_ORDER', 'DOOR_DELIVERY', 'REFILL', 'DIFF_BETWEEN_LAST_FIRST_DAYS',\n",
    "              'DIFF_BETWEEN_FIRST_CREATED_DAYS', 'FAV_DELIVERY_DAY_FRIDAY', 'FAV_DELIVERY_DAY_MONDAY', 'FAV_DELIVERY_DAY_SATURDAY', 'FAV_DELIVERY_DAY_SUNDAY', 'FAV_DELIVERY_DAY_THURSDAY',\n",
    "              'FAV_DELIVERY_DAY_TUESDAY','FAV_DELIVERY_DAY_WEDNESDAY', 'CITY_AUSTIN', 'CITY_DALLAS', 'CITY_HOUSTON', 'CITY_WACO' ]\n",
    "\n",
    "@pandas_udf(name=\"batch_predict\", is_permanent=True, stage_location=\"@udf\", replace=True, max_batch_size=100)\n",
    "def predict_batch(df: T.PandasDataFrame[float, float, float, float,\n",
    "                                          float, int,  int, int, int, int, int, int, int, int, int, int,\n",
    "                                          int, int, int, int]) -> T.PandasSeries[int]:\n",
    "       m = read_file('cust_churn.joblib') \n",
    "       df.columns = features\n",
    "       return m.predict(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07ca95a",
   "metadata": {},
   "source": [
    "## 5. Create a prediction table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4206ae9c",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.0 64-bit ('3.10.0')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/Users/jiaohongmei/.pyenv/versions/3.10.0/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from snowflake.snowpark import functions as F\n",
    "\n",
    "pred_table_name=\"CHURN_PREDICTIONS\"\n",
    "\n",
    "snowdf_test = session.table(tgt_table_name).drop('CUSTOMER_ID')\n",
    "inputs = snowdf_test.drop(\"RETAINED\")\n",
    "snowdf_results = snowdf_test.select(*inputs,\n",
    "                    predict_batch(*inputs).alias('PREDICTION'), \n",
    "                    (F.col('RETAINED')).alias('ACTUAL_LABEL')\n",
    "                    )\n",
    "\n",
    "snowdf_results.write.mode(\"overwrite\").save_as_table(pred_table_name)\n",
    "\n",
    "snowdf_results.to_pandas().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87ef3bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.0 64-bit ('3.10.0')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/Users/jiaohongmei/.pyenv/versions/3.10.0/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "4f01f2aed5982e444a4a24ac09b2c3e1a76b8203c372080d293ab10a26849f59"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
